{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Subhash\\anaconda3\\envs\\myenv3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 17:40:29.456 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Subhash\\anaconda3\\envs\\myenv3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the GROQ and OpenAI API keys\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "st.title(\"Gemma Model Document Q&A\")\n",
    "\n",
    "#llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Llama3-8b-8192\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(groq_api_key=groq_api_key, model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Answer the questions based on the provided context only.\n",
    "    Please provide the most accurate response based on the question\n",
    "    <context>\n",
    "    {context}\n",
    "    <context>\n",
    "    Questions:{input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.session_state.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "        \n",
    "        # Data Ingestion\n",
    "st.session_state.loader = PyPDFDirectoryLoader(\"C:\\Users\\Subhash\\OneDrive\\Desktop\\GENAI\\GEMMA\\pdf_downloads\")\n",
    "st.session_state.docs = st.session_state.loader.load()\n",
    "        \n",
    "        # Debugging: Check the number of documents loaded\n",
    "st.write(f\"Number of documents loaded: {len(st.session_state.docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.session_state.docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 17:41:05.617 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def vector_embedding():\n",
    "    if \"vectors\" not in st.session_state:\n",
    "        st.session_state.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "        \n",
    "        # Data Ingestion\n",
    "        st.session_state.loader = PyPDFDirectoryLoader(\"./pdf_dwonloads\")\n",
    "        st.session_state.docs = st.session_state.loader.load()\n",
    "        \n",
    "        # Debugging: Check the number of documents loaded\n",
    "        st.write(f\"Number of documents loaded: {len(st.session_state.docs)}\")\n",
    "        \n",
    "        if len(st.session_state.docs) == 0:\n",
    "            st.error(\"No documents found. Please check the directory and try again.\")\n",
    "            return\n",
    "\n",
    "        # Chunk Creation\n",
    "        st.session_state.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        st.session_state.final_documents = st.session_state.text_splitter.split_documents(st.session_state.docs[:20])\n",
    "        \n",
    "        # Debugging: Check the number of chunks created\n",
    "        st.write(f\"Number of chunks created: {len(st.session_state.final_documents)}\")\n",
    "        \n",
    "        if len(st.session_state.final_documents) == 0:\n",
    "            st.error(\"No document chunks created. Please check the splitting logic.\")\n",
    "            return\n",
    "        \n",
    "        # Vector Embedding\n",
    "        try:\n",
    "            st.session_state.vectors = FAISS.from_documents(st.session_state.final_documents, st.session_state.embeddings)\n",
    "            st.write(\"Vector Store DB is ready\")\n",
    "        except IndexError as e:\n",
    "            st.error(f\"Error creating vector store: {e}\")\n",
    "            st.write(\"Check if the embeddings are being generated correctly.\")\n",
    "\n",
    "prompt1 = st.text_input(\"Enter Your Question From Documents\")\n",
    "\n",
    "if st.button(\"Documents Embedding\"):\n",
    "    vector_embedding()\n",
    "\n",
    "import time\n",
    "\n",
    "if prompt1:\n",
    "    document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    retriever = st.session_state.vectors.as_retriever()\n",
    "    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "    \n",
    "    start = time.process_time()\n",
    "    response = retrieval_chain.invoke({'input': prompt1})\n",
    "    st.write(\"Response time: \", time.process_time() - start)\n",
    "    st.write(response['answer'])\n",
    "\n",
    "    # With a streamlit expander\n",
    "    with st.expander(\"Document Similarity Search\"):\n",
    "        # Find the relevant chunks\n",
    "        for i, doc in enumerate(response[\"context\"]):\n",
    "            st.write(doc.page_content)\n",
    "            st.write(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
